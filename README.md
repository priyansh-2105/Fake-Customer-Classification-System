
ğŸ•µï¸â€â™‚ï¸ Fake Customer Classifier

A small end-to-end machine learning project that generates synthetic e-commerce customer data, trains a classifier to detect fake customers, and serves predictions via a simple Streamlit app.

ğŸ”— Live Demo: https://fake-customer-classifier.streamlit.app

ğŸš€ Overview
This project demonstrates a full ML pipeline â€” from data generation to model deployment â€” using a reproducible and modular codebase. It includes tools for creating synthetic datasets, preprocessing data, training and saving models, and serving predictions interactively.

ğŸ§© Features
- ğŸ§  Synthetic Data Generation â†’ Easily create labeled e-commerce customer data.
- ğŸ§¹ Preprocessing Utilities â†’ Clean, encode, and prepare data for training.
- ğŸ¤– Training Pipeline â†’ Automates model training, evaluation, and saving artifacts.
- ğŸ“¦ Saved Artifacts â†’ Includes trained model and encoders for inference.
- ğŸŒ Streamlit App â†’ Simple user interface for real-time predictions.

ğŸ“ Project Structure
```
Fake-Customer-Classifier/
â”‚
â”œâ”€â”€ app.py                   # Streamlit app entrypoint
â”œâ”€â”€ configs/                 # Global paths, constants, and hyperparameters
â”œâ”€â”€ data/                    # Generated datasets (CSV files)
â”œâ”€â”€ models/                  # Saved models and label encoders
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ train_pipeline.py    # Model training and evaluation pipeline
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_generator.py    # Synthetic data generation
â”‚   â””â”€â”€ preprocessing.py     # Data preprocessing utilities
â”œâ”€â”€ utils/                   # Logging and custom exception handling
â””â”€â”€ requirements.txt         # Project dependencies
```

âš™ï¸ Quickstart
1. Environment Setup
   - Create a virtual environment
     - macOS/Linux:
       ```bash
       python -m venv venv && source venv/bin/activate
       ```
     - Windows (PowerShell):
       ```powershell
       python -m venv venv; venv\Scripts\activate
       ```
2. Install Dependencies
   ```bash
   pip install -r requirements.txt
   ```
3. Generate Synthetic Data
   ```bash
   python -c "from src.data_generator import generate_synthetic_data; generate_synthetic_data()"
   ```
4. Train the Model
   ```bash
   python -m pipeline.train_pipeline
   ```
5. Run the Streamlit App
   ```bash
   streamlit run app.py
   ```

ğŸ”§ Configuration
Modify parameters in `configs/config.py` to customize:
- Dataset size (`NUM_SAMPLES`)
- Train/test split
- File paths and storage directories
- Model hyperparameters

ğŸ“ Notes
- The data generator creates independent rows equal to `NUM_SAMPLES` (no fixed â€œcases per customerâ€).
- `customer_id` is not used as a feature; predictions are based on behavior/attributes only.

ğŸ§  Requirements
- Python 3.10 or higher
- Dependencies listed in `requirements.txt`

ğŸ’¡ Future Improvements
- Add explainability (SHAP/feature importance)
- Enhance UI with confidence scores and detailed insights

